{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b4ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from mads_datasets.base import BaseDatastreamer\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from src import datasets, metrics\n",
    "from src.models import ConvBlocks, CNNSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6793a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ptb': 'heart', 'arrhythmia': 'heart_big'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(363, 90)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tomllib\n",
    "\n",
    "dataset = 'ptb'\n",
    "\n",
    "datadir = Path('../data')\n",
    "configfile = Path(\"config.toml\")\n",
    "with configfile.open('rb') as f:\n",
    "    config = tomllib.load(f)\n",
    "print(config)\n",
    "trainfile = datadir / (config[dataset] + '_train.parq')\n",
    "testfile = datadir / (config[dataset] + '_test.parq')\n",
    "trainfile, testfile\n",
    "shape = (16, 12)\n",
    "traindataset = datasets.HeartDataset2D(trainfile, target=\"target\", shape=shape)\n",
    "testdataset = datasets.HeartDataset2D(testfile, target=\"target\", shape=shape)\n",
    "traindataset, testdataset\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "trainstreamer = BaseDatastreamer(traindataset, preprocessor = BasePreprocessor(), batchsize=32)\n",
    "teststreamer = BaseDatastreamer(testdataset, preprocessor = BasePreprocessor(), batchsize=32)\n",
    "len(trainstreamer), len(teststreamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37425ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated matrix size: 12\n",
      "Calculated flatten size: 384\n"
     ]
    }
   ],
   "source": [
    "model_settings = CNNSettings(\n",
    "    matrix_shape = (16, 12), #  Shape of the insert matrix\n",
    "    in_channels = 1,\n",
    "    hidden_size = 32, \n",
    "    num_layers = 3, #  Amount of convolutional layers to add\n",
    "    num_classes = 5, #  Amount of end classes to be determined \n",
    "    attention= True,\n",
    "    dense_activation='gelu'\n",
    "    )\n",
    "\n",
    "model = ConvBlocks(model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830f8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(trainstreamer.stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f114fb",
   "metadata": {},
   "source": [
    "# Testing CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e019ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:56: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:56: SyntaxWarning: invalid escape sequence '\\h'\n",
      "C:\\Users\\vmgir\\AppData\\Local\\Temp\\ipykernel_37012\\3443633461.py:56: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  2025-06-12 12:40:29.095 | INFO     | mltrainer.trainer:dir_add_timestamp:23 - Logging to logs\\heart2D\\20250612-124029\n",
      "\u001b[32m2025-06-27 18:54:47.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mLogging to logs\\heart2D\\20250627-185447\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 56.07it/s]\n",
      "\u001b[32m2025-06-27 18:54:50.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 0 train 0.7325 test 0.5952 metric ['0.7153', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 49.66it/s]\n",
      "\u001b[32m2025-06-27 18:54:52.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 1 train 0.5790 test 0.5665 metric ['0.7101', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 49.02it/s]\n",
      "\u001b[32m2025-06-27 18:54:53.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 2 train 0.5109 test 0.4856 metric ['0.7448', '0.5936']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 50.37it/s]\n",
      "\u001b[32m2025-06-27 18:54:55.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 3 train 0.5066 test 0.4925 metric ['0.7378', '0.6437']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 55.01it/s]\n",
      "\u001b[32m2025-06-27 18:54:57.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 4 train 0.4473 test 0.3904 metric ['0.7847', '0.6581']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 52.09it/s]\n",
      "\u001b[32m2025-06-27 18:54:58.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 5 train 0.3873 test 0.3743 metric ['0.8264', '0.8282']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 61.39it/s]\n",
      "\u001b[32m2025-06-27 18:54:59.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 6 train 0.3435 test 0.3071 metric ['0.8750', '0.8699']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 61.52it/s]\n",
      "\u001b[32m2025-06-27 18:55:01.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 7 train 0.3563 test 0.3334 metric ['0.8576', '0.8777']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 61.11it/s]\n",
      "\u001b[32m2025-06-27 18:55:02.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 8 train 0.3296 test 0.2801 metric ['0.8819', '0.8983']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:01<00:00, 45.00it/s]\n",
      "\u001b[32m2025-06-27 18:55:04.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 9 train 0.2986 test 0.2789 metric ['0.8767', '0.8288']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:15<00:00,  1.53s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWith no self attention\\n----------------------\\n\\n2025-06-12 12:40:29.095 | INFO     | mltrainer.trainer:dir_add_timestamp:23 - Logging to logs\\\\heart2D\\x8250612-124029\\n2025-06-12 12:40:40.574 | INFO     | mltrainer.trainer:report:198 - Epoch 0 train 0.6231 test 0.4953 metric ['0.8660', '0.8660', '0.4331']\\n2025-06-12 12:40:49.830 | INFO     | mltrainer.trainer:report:198 - Epoch 1 train 0.3396 test 0.2720 metric ['0.9345', '0.9345', '0.6792']\\n2025-06-12 12:40:58.755 | INFO     | mltrainer.trainer:report:198 - Epoch 2 train 0.2255 test 0.1732 metric ['0.9524', '0.9524', '0.7947']\\n2025-06-12 12:41:07.598 | INFO     | mltrainer.trainer:report:198 - Epoch 3 train 0.1747 test 0.1747 metric ['0.9540', '0.9540', '0.8135']\\n2025-06-12 12:41:16.644 | INFO     | mltrainer.trainer:report:198 - Epoch 4 train 0.1551 test 0.1417 metric ['0.9619', '0.9619', '0.8665']\\n2025-06-12 12:41:25.437 | INFO     | mltrainer.trainer:report:198 - Epoch 5 train 0.1408 test 0.1358 metric ['0.9665', '0.9665', '0.8527']\\n2025-06-12 12:41:34.270 | INFO     | mltrainer.trainer:report:198 - Epoch 6 train 0.1359 test 0.1339 metric ['0.9632', '0.9632', '0.8316']\\n2025-06-12 12:41:43.206 | INFO     | mltrainer.trainer:report:198 - Epoch 7 train 0.1280 test 0.1252 metric ['0.9701', '0.9701', '0.8852']\\n2025-06-12 12:41:51.908 | INFO     | mltrainer.trainer:report:198 - Epoch 8 train 0.1146 test 0.1115 metric ['0.9715', '0.9715', '0.8671']\\n2025-06-12 12:42:00.693 | INFO     | mltrainer.trainer:report:198 - Epoch 9 train 0.1091 test 0.1228 metric ['0.9674', '0.9674', '0.8505']\\n\\nWith Selfattention\\n------------------\\n2025-06-11 17:28:34.844 | INFO     | mltrainer.trainer:dir_add_timestamp:23 - Logging to logs\\\\heart2D\\x8250611-172834\\n2025-06-11 17:28:47.577 | INFO     | mltrainer.trainer:report:198 - Epoch 0 train 0.5928 test 0.3834 metric ['0.8879', '0.8879', '0.5407']\\n2025-06-11 17:28:58.848 | INFO     | mltrainer.trainer:report:198 - Epoch 1 train 0.3588 test 0.3643 metric ['0.8982', '0.8982', '0.6011']\\n2025-06-11 17:29:09.007 | INFO     | mltrainer.trainer:report:198 - Epoch 2 train 0.3078 test 0.2556 metric ['0.9409', '0.9409', '0.7152']\\n2025-06-11 17:29:19.159 | INFO     | mltrainer.trainer:report:198 - Epoch 3 train 0.2567 test 0.2526 metric ['0.9380', '0.9380', '0.7057']\\n2025-06-11 17:29:29.365 | INFO     | mltrainer.trainer:report:198 - Epoch 4 train 0.2216 test 0.2405 metric ['0.9341', '0.9341', '0.7038']\\n2025-06-11 17:29:40.296 | INFO     | mltrainer.trainer:report:198 - Epoch 5 train 0.2095 test 0.2105 metric ['0.9455', '0.9455', '0.7568']\\n2025-06-11 17:29:51.609 | INFO     | mltrainer.trainer:report:198 - Epoch 6 train 0.2077 test 0.2526 metric ['0.9352', '0.9352', '0.7884']\\n2025-06-11 17:30:04.300 | INFO     | mltrainer.trainer:report:198 - Epoch 7 train 0.1846 test 0.1844 metric ['0.9538', '0.9538', '0.8075']\\n2025-06-11 17:30:17.407 | INFO     | mltrainer.trainer:report:198 - Epoch 8 train 0.1897 test 0.1698 metric ['0.9614', '0.9614', '0.8498']\\n2025-06-11 17:30:29.265 | INFO     | mltrainer.trainer:report:198 - Epoch 9 train 0.1696 test 0.1825 metric ['0.9517', '0.9517', '0.7818']\\n\\nWith MultiHead Self attention\\n------------------\\n2025-06-11 17:37:27.088 | INFO     | mltrainer.trainer:dir_add_timestamp:23 - Logging to logs\\\\heart2D\\x8250611-173727\\n2025-06-11 17:37:42.383 | INFO     | mltrainer.trainer:report:198 - Epoch 0 train 0.5536 test 0.3658 metric ['0.9076', '0.9076', '0.6114']\\n2025-06-11 17:37:55.318 | INFO     | mltrainer.trainer:report:198 - Epoch 1 train 0.3139 test 0.2612 metric ['0.9352', '0.9352', '0.7102']\\n2025-06-11 17:38:07.132 | INFO     | mltrainer.trainer:report:198 - Epoch 2 train 0.2405 test 0.2361 metric ['0.9405', '0.9405', '0.7631']\\n2025-06-11 17:38:18.777 | INFO     | mltrainer.trainer:report:198 - Epoch 3 train 0.1933 test 0.1941 metric ['0.9559', '0.9559', '0.8365']\\n2025-06-11 17:38:32.020 | INFO     | mltrainer.trainer:report:198 - Epoch 4 train 0.1696 test 0.1644 metric ['0.9561', '0.9561', '0.7823']\\n2025-06-11 17:38:43.319 | INFO     | mltrainer.trainer:report:198 - Epoch 5 train 0.1572 test 0.1405 metric ['0.9671', '0.9671', '0.8532']\\n2025-06-11 17:38:54.447 | INFO     | mltrainer.trainer:report:198 - Epoch 6 train 0.1335 test 0.1340 metric ['0.9674', '0.9674', '0.8493']\\n2025-06-11 17:39:10.569 | INFO     | mltrainer.trainer:report:198 - Epoch 7 train 0.1356 test 0.1371 metric ['0.9644', '0.9644', '0.8481']\\n2025-06-11 17:39:23.101 | INFO     | mltrainer.trainer:report:198 - Epoch 8 train 0.1268 test 0.1497 metric ['0.9614', '0.9614', '0.8267']\\n2025-06-11 17:39:36.016 | INFO     | mltrainer.trainer:report:198 - Epoch 9 train 0.1273 test 0.1224 metric ['0.9678', '0.9678', '0.8565']\\n\\nEpoch 9 train 0.3166 test 0.3350 metric ['0.8524', '0.8524', '0.8636']\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = metrics.Precision('micro')\n",
    "recall = metrics.Recall('macro')\n",
    "accuracy = metrics.Accuracy()\n",
    "\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(\"1D world\")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    optimizer = torch.optim.Adam\n",
    "\n",
    "    settings = TrainerSettings(\n",
    "        epochs=10,\n",
    "        metrics=[accuracy, recall],\n",
    "        logdir=\"logs/heart2D\",\n",
    "        train_steps=len(trainstreamer) // 5,\n",
    "        valid_steps=len(teststreamer) // 5,\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "        scheduler_kwargs=None,\n",
    "        earlystop_kwargs=None\n",
    "    )\n",
    "\n",
    "    # modify the tags when you change them!\n",
    "    mlflow.set_tag(\"model\", \"Conv2D\")\n",
    "    mlflow.set_tag(\"dataset\", \"heart_small_binary\")\n",
    "    mlflow.log_param(\"scheduler\", \"None\")\n",
    "    mlflow.log_param(\"earlystop\", \"None\")\n",
    "\n",
    "    mlflow.log_params(model_settings.__dict__)\n",
    "    mlflow.log_param(\"epochs\", settings.epochs)\n",
    "    mlflow.log_param(\"modeltype\", \"CNN\")\n",
    "    mlflow.log_param(\"shape0\", shape[0])\n",
    "    mlflow.log_param(\"optimizer\", str(optimizer))\n",
    "    mlflow.log_params(settings.optimizer_kwargs)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        traindataloader=trainstreamer.stream(),\n",
    "        validdataloader=teststreamer.stream(),\n",
    "        scheduler=None,\n",
    "        )\n",
    "    trainer.loop()\n",
    "\n",
    "\n",
    "# No SelfAttention\n",
    "\"\"\"\n",
    "With no self attention\n",
    "----------------------\n",
    "\n",
    "2025-06-12 12:40:29.095 | INFO     | mltrainer.trainer:dir_add_timestamp:23 - Logging to logs\\heart2D\\20250612-124029\n",
    "2025-06-12 12:40:40.574 | INFO     | mltrainer.trainer:report:198 - Epoch 0 train 0.6231 test 0.4953 metric ['0.8660', '0.8660', '0.4331']\n",
    "2025-06-12 12:40:49.830 | INFO     | mltrainer.trainer:report:198 - Epoch 1 train 0.3396 test 0.2720 metric ['0.9345', '0.9345', '0.6792']\n",
    "2025-06-12 12:40:58.755 | INFO     | mltrainer.trainer:report:198 - Epoch 2 train 0.2255 test 0.1732 metric ['0.9524', '0.9524', '0.7947']\n",
    "2025-06-12 12:41:07.598 | INFO     | mltrainer.trainer:report:198 - Epoch 3 train 0.1747 test 0.1747 metric ['0.9540', '0.9540', '0.8135']\n",
    "2025-06-12 12:41:16.644 | INFO     | mltrainer.trainer:report:198 - Epoch 4 train 0.1551 test 0.1417 metric ['0.9619', '0.9619', '0.8665']\n",
    "2025-06-12 12:41:25.437 | INFO     | mltrainer.trainer:report:198 - Epoch 5 train 0.1408 test 0.1358 metric ['0.9665', '0.9665', '0.8527']\n",
    "2025-06-12 12:41:34.270 | INFO     | mltrainer.trainer:report:198 - Epoch 6 train 0.1359 test 0.1339 metric ['0.9632', '0.9632', '0.8316']\n",
    "2025-06-12 12:41:43.206 | INFO     | mltrainer.trainer:report:198 - Epoch 7 train 0.1280 test 0.1252 metric ['0.9701', '0.9701', '0.8852']\n",
    "2025-06-12 12:41:51.908 | INFO     | mltrainer.trainer:report:198 - Epoch 8 train 0.1146 test 0.1115 metric ['0.9715', '0.9715', '0.8671']\n",
    "2025-06-12 12:42:00.693 | INFO     | mltrainer.trainer:report:198 - Epoch 9 train 0.1091 test 0.1228 metric ['0.9674', '0.9674', '0.8505']\n",
    "\n",
    "With Selfattention\n",
    "------------------\n",
    "2025-06-11 17:28:34.844 | INFO     | mltrainer.trainer:dir_add_timestamp:23 - Logging to logs\\heart2D\\20250611-172834\n",
    "2025-06-11 17:28:47.577 | INFO     | mltrainer.trainer:report:198 - Epoch 0 train 0.5928 test 0.3834 metric ['0.8879', '0.8879', '0.5407']\n",
    "2025-06-11 17:28:58.848 | INFO     | mltrainer.trainer:report:198 - Epoch 1 train 0.3588 test 0.3643 metric ['0.8982', '0.8982', '0.6011']\n",
    "2025-06-11 17:29:09.007 | INFO     | mltrainer.trainer:report:198 - Epoch 2 train 0.3078 test 0.2556 metric ['0.9409', '0.9409', '0.7152']\n",
    "2025-06-11 17:29:19.159 | INFO     | mltrainer.trainer:report:198 - Epoch 3 train 0.2567 test 0.2526 metric ['0.9380', '0.9380', '0.7057']\n",
    "2025-06-11 17:29:29.365 | INFO     | mltrainer.trainer:report:198 - Epoch 4 train 0.2216 test 0.2405 metric ['0.9341', '0.9341', '0.7038']\n",
    "2025-06-11 17:29:40.296 | INFO     | mltrainer.trainer:report:198 - Epoch 5 train 0.2095 test 0.2105 metric ['0.9455', '0.9455', '0.7568']\n",
    "2025-06-11 17:29:51.609 | INFO     | mltrainer.trainer:report:198 - Epoch 6 train 0.2077 test 0.2526 metric ['0.9352', '0.9352', '0.7884']\n",
    "2025-06-11 17:30:04.300 | INFO     | mltrainer.trainer:report:198 - Epoch 7 train 0.1846 test 0.1844 metric ['0.9538', '0.9538', '0.8075']\n",
    "2025-06-11 17:30:17.407 | INFO     | mltrainer.trainer:report:198 - Epoch 8 train 0.1897 test 0.1698 metric ['0.9614', '0.9614', '0.8498']\n",
    "2025-06-11 17:30:29.265 | INFO     | mltrainer.trainer:report:198 - Epoch 9 train 0.1696 test 0.1825 metric ['0.9517', '0.9517', '0.7818']\n",
    "\n",
    "With MultiHead Self attention\n",
    "------------------\n",
    "2025-06-11 17:37:27.088 | INFO     | mltrainer.trainer:dir_add_timestamp:23 - Logging to logs\\heart2D\\20250611-173727\n",
    "2025-06-11 17:37:42.383 | INFO     | mltrainer.trainer:report:198 - Epoch 0 train 0.5536 test 0.3658 metric ['0.9076', '0.9076', '0.6114']\n",
    "2025-06-11 17:37:55.318 | INFO     | mltrainer.trainer:report:198 - Epoch 1 train 0.3139 test 0.2612 metric ['0.9352', '0.9352', '0.7102']\n",
    "2025-06-11 17:38:07.132 | INFO     | mltrainer.trainer:report:198 - Epoch 2 train 0.2405 test 0.2361 metric ['0.9405', '0.9405', '0.7631']\n",
    "2025-06-11 17:38:18.777 | INFO     | mltrainer.trainer:report:198 - Epoch 3 train 0.1933 test 0.1941 metric ['0.9559', '0.9559', '0.8365']\n",
    "2025-06-11 17:38:32.020 | INFO     | mltrainer.trainer:report:198 - Epoch 4 train 0.1696 test 0.1644 metric ['0.9561', '0.9561', '0.7823']\n",
    "2025-06-11 17:38:43.319 | INFO     | mltrainer.trainer:report:198 - Epoch 5 train 0.1572 test 0.1405 metric ['0.9671', '0.9671', '0.8532']\n",
    "2025-06-11 17:38:54.447 | INFO     | mltrainer.trainer:report:198 - Epoch 6 train 0.1335 test 0.1340 metric ['0.9674', '0.9674', '0.8493']\n",
    "2025-06-11 17:39:10.569 | INFO     | mltrainer.trainer:report:198 - Epoch 7 train 0.1356 test 0.1371 metric ['0.9644', '0.9644', '0.8481']\n",
    "2025-06-11 17:39:23.101 | INFO     | mltrainer.trainer:report:198 - Epoch 8 train 0.1268 test 0.1497 metric ['0.9614', '0.9614', '0.8267']\n",
    "2025-06-11 17:39:36.016 | INFO     | mltrainer.trainer:report:198 - Epoch 9 train 0.1273 test 0.1224 metric ['0.9678', '0.9678', '0.8565']\n",
    "\n",
    "Epoch 9 train 0.3166 test 0.3350 metric ['0.8524', '0.8524', '0.8636']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e7765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0009], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0233], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from src.models import MultiHeadSelfAtt\n",
    "for layer in model.convolutions:\n",
    "    if isinstance(layer, MultiHeadSelfAtt):\n",
    "        print(layer.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea710d5c",
   "metadata": {},
   "source": [
    "# Testing RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b138094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ptb': 'heart', 'arrhythmia': 'heart_big'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(363, 90)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tomllib\n",
    "\n",
    "dataset = 'ptb'\n",
    "\n",
    "datadir = Path('../data')\n",
    "configfile = Path(\"config.toml\")\n",
    "\n",
    "with configfile.open('rb') as f:\n",
    "    config = tomllib.load(f)\n",
    "print(config)\n",
    "\n",
    "trainfile = datadir / (config[dataset] + '_train.parq')\n",
    "testfile = datadir / (config[dataset] + '_test.parq')\n",
    "trainfile, testfile\n",
    "\n",
    "traindataset = datasets.HeartDataset1D(trainfile, target=\"target\")\n",
    "testdataset = datasets.HeartDataset1D(testfile, target=\"target\")\n",
    "traindataset, testdataset\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "trainstreamer = BaseDatastreamer(traindataset, preprocessor = BasePreprocessor(), batchsize=32)\n",
    "teststreamer = BaseDatastreamer(testdataset, preprocessor = BasePreprocessor(), batchsize=32)\n",
    "len(trainstreamer), len(teststreamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdff001",
   "metadata": {},
   "source": [
    "## GRU Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564f53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import GRUSettings, GRUmodel\n",
    "\n",
    "model_settings = GRUSettings(\n",
    "    hidden_size = 32,\n",
    "    input_size = 1,\n",
    "    num_layers = 2,\n",
    "    output_size = 5,\n",
    "    dropout = 0.2,\n",
    "    attention_dropout=0.3\n",
    ")\n",
    "\n",
    "model = GRUmodel(model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc4a0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-27 18:55:04.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mLogging to logs\\heart1D\\20250627-185504\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:13<00:00,  5.40it/s]\n",
      "\u001b[32m2025-06-27 18:55:18.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 0 train 0.8570 test 0.5848 metric ['0.7483', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:13<00:00,  5.33it/s]\n",
      "\u001b[32m2025-06-27 18:55:32.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 1 train 0.6089 test 0.6123 metric ['0.6997', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:13<00:00,  5.49it/s]\n",
      "\u001b[32m2025-06-27 18:55:46.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 2 train 0.5833 test 0.6063 metric ['0.7066', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:13<00:00,  5.27it/s]\n",
      "\u001b[32m2025-06-27 18:56:00.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 3 train 0.5857 test 0.5569 metric ['0.7552', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:12<00:00,  5.67it/s]\n",
      "\u001b[32m2025-06-27 18:56:13.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 4 train 0.5880 test 0.6161 metric ['0.7049', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:14<00:00,  5.14it/s]\n",
      "\u001b[32m2025-06-27 18:56:28.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 5 train 0.6020 test 0.6216 metric ['0.7083', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:13<00:00,  5.29it/s]\n",
      "\u001b[32m2025-06-27 18:56:42.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 6 train 0.5934 test 0.5918 metric ['0.7222', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:13<00:00,  5.29it/s]\n",
      "\u001b[32m2025-06-27 18:56:56.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 7 train 0.5835 test 0.5736 metric ['0.7396', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:12<00:00,  5.66it/s]\n",
      "\u001b[32m2025-06-27 18:57:10.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 8 train 0.5949 test 0.5995 metric ['0.7135', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:13<00:00,  5.29it/s]\n",
      "\u001b[32m2025-06-27 18:57:24.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 9 train 0.6013 test 0.5920 metric ['0.7240', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [02:19<00:00, 13.96s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(\"1D Escapades\")\n",
    "\n",
    "\n",
    "precision = metrics.Precision('micro')\n",
    "recall = metrics.Recall('macro')\n",
    "accuracy = metrics.Accuracy()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    optimizer = torch.optim.Adam\n",
    "    settings = TrainerSettings(\n",
    "        epochs=10,\n",
    "        metrics=[accuracy, recall],\n",
    "        logdir=\"logs/heart1D\",\n",
    "        train_steps=len(trainstreamer) // 5,\n",
    "        valid_steps=len(teststreamer) // 5,\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "        scheduler_kwargs=None,\n",
    "        earlystop_kwargs=None\n",
    "    )\n",
    "\n",
    "    # modify the tags when you change them!\n",
    "    mlflow.set_tag(\"model\", \"RNN\")\n",
    "    mlflow.set_tag(\"dataset\", \"heart_small_binary\")\n",
    "    mlflow.log_param(\"scheduler\", \"None\")\n",
    "    mlflow.log_param(\"earlystop\", \"None\")\n",
    "\n",
    "    mlflow.log_params(model_settings.__dict__)\n",
    "    mlflow.log_param(\"epochs\", settings.epochs)\n",
    "    mlflow.log_param(\"shape0\", shape[0])\n",
    "    mlflow.log_param(\"modeltype\", \"RNN\")\n",
    "    mlflow.log_param(\"optimizer\", str(optimizer))\n",
    "    mlflow.log_params(settings.optimizer_kwargs)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        traindataloader=trainstreamer.stream(),\n",
    "        validdataloader=teststreamer.stream(),\n",
    "        scheduler=None,\n",
    "        )\n",
    "    trainer.loop()\n",
    "\n",
    "\n",
    "# No SelfAttention\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581394b",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdb55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import LSTMSettings, LSTMmodel\n",
    "\n",
    "model_settings = LSTMSettings(\n",
    "    hidden_size = 32,\n",
    "    input_size = 1,\n",
    "    num_layers = 2,\n",
    "    output_size = 5,\n",
    "    dropout = 0.2,\n",
    "    attention_dropout=0.3\n",
    ")\n",
    "\n",
    "model = LSTMmodel(model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84eb70dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-27 18:57:24.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mLogging to logs\\heart1D\\20250627-185724\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00,  9.91it/s]\n",
      "\u001b[32m2025-06-27 18:57:32.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 0 train 0.9258 test 0.5928 metric ['0.7240', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00, 10.28it/s]\n",
      "\u001b[32m2025-06-27 18:57:39.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 1 train 0.5925 test 0.6021 metric ['0.7205', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00,  9.57it/s]\n",
      "\u001b[32m2025-06-27 18:57:47.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 2 train 0.6042 test 0.5703 metric ['0.7431', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00,  9.61it/s]\n",
      "\u001b[32m2025-06-27 18:57:55.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 3 train 0.6033 test 0.6100 metric ['0.7083', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00, 10.13it/s]\n",
      "\u001b[32m2025-06-27 18:58:02.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 4 train 0.5836 test 0.5968 metric ['0.7188', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00, 10.28it/s]\n",
      "\u001b[32m2025-06-27 18:58:09.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 5 train 0.5948 test 0.5954 metric ['0.7170', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00,  9.23it/s]\n",
      "\u001b[32m2025-06-27 18:58:18.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 6 train 0.5920 test 0.6143 metric ['0.6944', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00,  9.84it/s]\n",
      "\u001b[32m2025-06-27 18:58:25.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 7 train 0.5897 test 0.5920 metric ['0.7222', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:07<00:00, 10.13it/s]\n",
      "\u001b[32m2025-06-27 18:58:33.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 8 train 0.5951 test 0.5835 metric ['0.7309', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 72/72 [00:08<00:00,  8.12it/s]\n",
      "\u001b[32m2025-06-27 18:58:42.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mEpoch 9 train 0.5941 test 0.5685 metric ['0.7552', '0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [01:17<00:00,  7.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mads_exam.db\")\n",
    "mlflow.set_experiment(\"1D Escapades\")\n",
    "\n",
    "\n",
    "precision = metrics.Precision('micro')\n",
    "recall = metrics.Recall('macro')\n",
    "accuracy = metrics.Accuracy()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    optimizer = torch.optim.Adam\n",
    "    settings = TrainerSettings(\n",
    "        epochs=10,\n",
    "        metrics=[accuracy, recall],\n",
    "        logdir=\"logs/heart1D\",\n",
    "        train_steps=len(trainstreamer) // 5,\n",
    "        valid_steps=len(teststreamer) // 5,\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "        scheduler_kwargs=None,\n",
    "        earlystop_kwargs=None\n",
    "    )\n",
    "\n",
    "    # modify the tags when you change them!\n",
    "    mlflow.set_tag(\"model\", \"RNN\")\n",
    "    mlflow.set_tag(\"dataset\", \"heart_small_binary\")\n",
    "    mlflow.log_param(\"scheduler\", \"None\")\n",
    "    mlflow.log_param(\"earlystop\", \"None\")\n",
    "\n",
    "    mlflow.log_params(model_settings.__dict__)\n",
    "    mlflow.log_param(\"epochs\", settings.epochs)\n",
    "    mlflow.log_param(\"shape0\", shape[0])\n",
    "    mlflow.log_param(\"modeltype\", \"RNN\")\n",
    "    mlflow.log_param(\"optimizer\", str(optimizer))\n",
    "    mlflow.log_params(settings.optimizer_kwargs)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        traindataloader=trainstreamer.stream(),\n",
    "        validdataloader=teststreamer.stream(),\n",
    "        scheduler=None,\n",
    "        )\n",
    "    trainer.loop()\n",
    "\n",
    "\n",
    "# No SelfAttention\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0a116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
